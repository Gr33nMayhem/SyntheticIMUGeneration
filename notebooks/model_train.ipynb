{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter, resample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy import misc\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:41.284842Z",
     "end_time": "2024-03-19T14:57:41.301824Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x144b203f070>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if cuda is available\n",
    "print(torch.cuda.is_available())\n",
    "torch.autograd.set_detect_anomaly(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:41.586461Z",
     "end_time": "2024-03-19T14:57:41.599507Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "data_path = '../data/VTT_ConIot_Dataset'\n",
    "IMU_path = data_path + '/IMU'\n",
    "Keypoint_path = data_path + '/Keypoint'\n",
    "activities = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "users = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:41.871521Z",
     "end_time": "2024-03-19T14:57:41.884589Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def create_keypoint_and_imu_data(subject, activity):\n",
    "    # check if file exists\n",
    "    if not os.path.exists(Keypoint_path + f'/Subject_{subject:02d}_Task_{activity}.m2ts_keyPoints.csv'):\n",
    "        print(f'Keypoint file for Subject_{subject:02d}_Task_{activity} does not exist')\n",
    "        # return two empty dataframes\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    keypoint_data = pd.read_csv(Keypoint_path + f'/Subject_{subject:02d}_Task_{activity}.m2ts_keyPoints.csv')\n",
    "    imu_data = pd.read_csv(IMU_path + f'/activity_{activity}_user_{subject}_combined.csv')\n",
    "    # only keep the columns in imu data that are of accelerometer, i.e. that have _A in the name\n",
    "    imu_data = imu_data[[col for col in imu_data.columns if '_A' in col]]\n",
    "    # remove frame_number and timestamp columns from keypoint data\n",
    "    keypoint_data = keypoint_data.drop(columns=['frame_number', 'timestamp'])\n",
    "    keypoint_data['subject'] = subject\n",
    "    keypoint_data['activity'] = activity\n",
    "    imu_data['subject'] = subject\n",
    "    imu_data['activity'] = activity\n",
    "    # make sure subject and activity are of type float\n",
    "    keypoint_data['subject'] = keypoint_data['subject'].astype(float)\n",
    "    keypoint_data['activity'] = keypoint_data['activity'].astype(float)\n",
    "    imu_data['subject'] = imu_data['subject'].astype(float)\n",
    "    imu_data['activity'] = imu_data['activity'].astype(float)\n",
    "    return keypoint_data, imu_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:42.143607Z",
     "end_time": "2024-03-19T14:57:42.163657Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def create_relative_keypoints(df_keypoints):\n",
    "    '''\n",
    "    \"keypoints\": [\n",
    "            \"nose\",\"left_eye\",\"right_eye\",\"left_ear\",\"right_ear\",\n",
    "            \"left_shoulder\",\"right_shoulder\",\"left_elbow\",\"right_elbow\",\n",
    "            \"left_wrist\",\"right_wrist\",\"left_hip\",\"right_hip\",\n",
    "            \"left_knee\",\"right_knee\",\"left_ankle\",\"right_ankle\"\n",
    "        ],\n",
    "    \"corresponding points\":[\n",
    "            \"0\", \"1\", \"2\", \"3\", \"4\",\n",
    "            \"5\", \"6\", \"7\", \"8\",\n",
    "            \"9\", \"10\", \"11\", \"12\",\n",
    "            \"13\", \"14\", \"15\", \"16\"\n",
    "        ]\n",
    "    There are 17 points with each point having their x, y and confidence values\n",
    "    :param df_keypoints:\n",
    "    :return:\n",
    "    '''\n",
    "    # drop the column \"detection_score\" as they are all high\n",
    "    df_keypoints = df_keypoints.drop(columns=['detection_score'])\n",
    "    # create a weighted average column of the x and y of nose, left eye, right eye, left ear and right ear and call it x_head, y_head, prob_head\n",
    "    # where the columns for x and y are labelled as x0,y0,prob0,x1,y1,prob1,....,x16,y16,prob16\n",
    "    # get the x and y values for the nose, left eye, right eye, left ear and right ear\n",
    "    x_head = (df_keypoints['x0'] * df_keypoints['prob0'] + df_keypoints['x1'] * df_keypoints['prob1'] +\n",
    "              df_keypoints['x2'] * df_keypoints['prob2'] + df_keypoints['x3'] * df_keypoints['prob3'] +\n",
    "              df_keypoints['x4'] * df_keypoints['prob4']) / (df_keypoints['prob0'] + df_keypoints['prob1'] +\n",
    "                                                             df_keypoints['prob2'] + df_keypoints['prob3'] +\n",
    "                                                             df_keypoints['prob4'])\n",
    "\n",
    "    y_head = (df_keypoints['y0'] * df_keypoints['prob0'] + df_keypoints['y1'] * df_keypoints['prob1'] +\n",
    "              df_keypoints['y2'] * df_keypoints['prob2'] + df_keypoints['y3'] * df_keypoints['prob3'] +\n",
    "              df_keypoints['y4'] * df_keypoints['prob4']) / (df_keypoints['prob0'] + df_keypoints['prob1'] +\n",
    "                                                             df_keypoints['prob2'] + df_keypoints['prob3'] +\n",
    "                                                             df_keypoints['prob4'])\n",
    "    # set prob_head as the maximum of the probabilities of the nose, left eye, right eye, left ear and right ear\n",
    "    prob_head = df_keypoints[['prob0', 'prob1', 'prob2', 'prob3', 'prob4']].max(axis=1)\n",
    "\n",
    "    # add the columns to the dataframe\n",
    "    df_keypoints['x_head'] = x_head\n",
    "    df_keypoints['y_head'] = y_head\n",
    "    df_keypoints['prob_head'] = prob_head\n",
    "\n",
    "    # drop the columns for the nose, left eye, right eye, left ear and right ear\n",
    "    df_keypoints = df_keypoints.drop(columns=['x0', 'y0', 'prob0', 'x1', 'y1', 'prob1', 'x2', 'y2', 'prob2',\n",
    "                                              'x3', 'y3', 'prob3', 'x4', 'y4', 'prob4'])\n",
    "\n",
    "    # convert the x and y values to be relative to the head\n",
    "    for i in range(5, 17):\n",
    "        df_keypoints[f'x{i}'] = df_keypoints[f'x{i}'] - df_keypoints['x_head']\n",
    "        df_keypoints[f'y{i}'] = df_keypoints[f'y{i}'] - df_keypoints['y_head']\n",
    "\n",
    "    # drop the columns for the x and y values of the head\n",
    "    df_keypoints = df_keypoints.drop(columns=['x_head', 'y_head', 'prob_head'])\n",
    "\n",
    "    return df_keypoints\n",
    "\n",
    "\n",
    "def processed_data():\n",
    "    full_keypoint_data = pd.DataFrame()\n",
    "    full_imu_data = pd.DataFrame()\n",
    "    for activity in activities:\n",
    "        for user in users:\n",
    "            keypoint_data, imu_data = create_keypoint_and_imu_data(user, activity)\n",
    "            full_keypoint_data = pd.concat([full_keypoint_data, keypoint_data])\n",
    "            full_imu_data = pd.concat([full_imu_data, imu_data])\n",
    "\n",
    "    # pre-pocess by removing the extra time stamps fom either keypoint or imu data\n",
    "    # per participant and activity pair there should be 4x the number of imu data points as keypoint data points\n",
    "    cropped_keypoint_data = pd.DataFrame()\n",
    "    cropped_imu_data = pd.DataFrame()\n",
    "    for activity in activities:\n",
    "        for user in users:\n",
    "            # print shape of keypoint and imu data\n",
    "            keypoint_data = full_keypoint_data[\n",
    "                (full_keypoint_data['subject'] == user) & (full_keypoint_data['activity'] == activity)]\n",
    "            imu_data = full_imu_data[(full_imu_data['subject'] == user) & (full_imu_data['activity'] == activity)]\n",
    "\n",
    "            # if either of the data is empty, skip\n",
    "            if keypoint_data.shape[0] == 0 or imu_data.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            if keypoint_data.shape[0] * 4 > imu_data.shape[0]:\n",
    "                # remove the extra keypoint data\n",
    "                keypoint_data = keypoint_data.iloc[:imu_data.shape[0] // 4]\n",
    "            else:\n",
    "                # remove the extra imu data\n",
    "                imu_data = imu_data.iloc[:keypoint_data.shape[0] * 4]\n",
    "            # remove keypoint values such that keypoint data is multiple of 25\n",
    "            keypoint_data = keypoint_data.iloc[:keypoint_data.shape[0] // 25 * 25]\n",
    "\n",
    "            # remove imu values such that imu data is multiple of 100\n",
    "            imu_data = imu_data.iloc[:imu_data.shape[0] // 100 * 100]\n",
    "\n",
    "            # make copy of the columns subject and activity before dropping\n",
    "            subject_col = imu_data['subject']\n",
    "            activity_col = imu_data['activity']\n",
    "            imu_data = imu_data.drop(columns=['subject', 'activity'])\n",
    "            # resample the imu data to be the same length as the keypoint data\n",
    "            imu_resampled = resample(imu_data, keypoint_data.shape[0])\n",
    "            # create a pd dataframe from the resampled data using the columns in imu_data\n",
    "            imu_data = pd.DataFrame(imu_resampled, columns=imu_data.columns)\n",
    "            # add the subject and activity columns back\n",
    "            imu_data['subject'] = subject_col\n",
    "            imu_data['activity'] = activity_col\n",
    "\n",
    "            cropped_keypoint_data = pd.concat([cropped_keypoint_data, keypoint_data])\n",
    "            cropped_imu_data = pd.concat([cropped_imu_data, imu_data])\n",
    "\n",
    "    # reset the index keypoint\n",
    "    cropped_keypoint_data = cropped_keypoint_data.reset_index(drop=True)\n",
    "    # preprocess the keypoints for each point of interest from pose estimation\n",
    "    cropped_keypoint_data = create_relative_keypoints(cropped_keypoint_data)\n",
    "\n",
    "    # reset the index for imu\n",
    "    cropped_imu_data = cropped_imu_data.reset_index(drop=True)\n",
    "\n",
    "    # create a new df between 25 key-points and 100 IMU data points for each activity and user\n",
    "    # with columns start, end, subject, activity\n",
    "    sliding_windows = pd.DataFrame(columns=['start', 'end', 'subject', 'activity'])\n",
    "\n",
    "    for activity in activities:\n",
    "        for user in users:\n",
    "            # preserve the index\n",
    "            keypoint_data = cropped_keypoint_data[\n",
    "                (cropped_keypoint_data['subject'] == user) & (cropped_keypoint_data['activity'] == activity)]\n",
    "            # if either of the data is empty, skip\n",
    "            if keypoint_data.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            # split the data into windows of 25\n",
    "            for i in range(0, keypoint_data.shape[0], 25):\n",
    "                # check if the window has 25 elements\n",
    "                if i + 25 > keypoint_data.shape[0]:\n",
    "                    continue\n",
    "                # get the start and end index of the window in cropped_keypoint_data\n",
    "                start = keypoint_data.index[i]\n",
    "                end = keypoint_data.index[i + 25 - 1]\n",
    "                # concat to the sliding_windows dataframe\n",
    "                sliding_windows = pd.concat([sliding_windows, pd.DataFrame(\n",
    "                    {'start': [start], 'end': [end], 'subject': [user], 'activity': [activity]})])\n",
    "\n",
    "    sliding_windows = sliding_windows.reset_index(drop=True)\n",
    "\n",
    "    # normalize the keypoint data\n",
    "    # create a copy of column activity and subject before dropping\n",
    "    activity = cropped_keypoint_data['activity']\n",
    "    subject = cropped_keypoint_data['subject']\n",
    "    # create a copy of all columns starting with prob\n",
    "    prob_cols = cropped_keypoint_data.filter(regex='prob').copy()\n",
    "    # drop the columns activity, subject and all columns starting with prob\n",
    "    cropped_keypoint_data = cropped_keypoint_data.drop(columns=['activity', 'subject'])\n",
    "    cropped_keypoint_data = cropped_keypoint_data.drop(columns=cropped_keypoint_data.filter(regex='prob').columns)\n",
    "    # Do a normalization\n",
    "    scaler = StandardScaler()\n",
    "    cropped_keypoint_data = pd.DataFrame(scaler.fit_transform(cropped_keypoint_data),\n",
    "                                         columns=cropped_keypoint_data.columns)\n",
    "    # add the columns activity and subject back\n",
    "    cropped_keypoint_data['activity'] = activity\n",
    "    cropped_keypoint_data['subject'] = subject\n",
    "    # add the columns starting with prob back\n",
    "    cropped_keypoint_data = pd.concat([cropped_keypoint_data, prob_cols], axis=1)\n",
    "\n",
    "    return cropped_keypoint_data, cropped_imu_data, sliding_windows\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:42.680564Z",
     "end_time": "2024-03-19T14:57:42.695761Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoint file for Subject_06_Task_11 does not exist\n"
     ]
    }
   ],
   "source": [
    "keypoint_data, imu_data, sliding_windows = processed_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:43.205236Z",
     "end_time": "2024-03-19T14:58:31.932252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286100, 38)\n",
      "(286100, 11)\n",
      "RangeIndex(start=0, stop=286100, step=1)\n",
      "RangeIndex(start=0, stop=286100, step=1)\n",
      "subject\n",
      "True    286100\n",
      "Name: count, dtype: int64\n",
      "1.0\n",
      "1.0\n",
      "             x5        y5        x6        y6        x7        y7        x8  \\\n",
      "count 281934.00 281934.00 281934.00 281934.00 281934.00 281934.00 281934.00   \n",
      "mean       0.00      0.00     -0.00      0.00      0.00      0.00     -0.00   \n",
      "std        1.00      1.00      1.00      1.00      1.00      1.00      1.00   \n",
      "min       -7.25    -16.01     -7.73    -18.31    -10.03     -6.73     -9.30   \n",
      "25%       -0.81     -0.37     -0.83     -0.48     -0.76     -0.50     -0.70   \n",
      "50%        0.05      0.09     -0.03     -0.02      0.10      0.11     -0.02   \n",
      "75%        0.85      0.62      0.81      0.67      0.80      0.64      0.67   \n",
      "max       11.64     18.05      9.80      8.41      4.14     11.48      6.79   \n",
      "\n",
      "             y8        x9        y9  ...     prob7     prob8     prob9  \\\n",
      "count 281934.00 281934.00 281934.00  ... 286100.00 286100.00 286100.00   \n",
      "mean       0.00     -0.00     -0.00  ...      0.22      0.23      0.27   \n",
      "std        1.00      1.00      1.00  ...      0.13      0.15      0.19   \n",
      "min       -6.83    -10.27     -4.46  ...      0.00      0.00      0.00   \n",
      "25%       -0.44     -0.70     -0.50  ...      0.11      0.12      0.12   \n",
      "50%        0.12     -0.07      0.22  ...      0.21      0.23      0.25   \n",
      "75%        0.56      0.70      0.60  ...      0.29      0.32      0.38   \n",
      "max       11.23      4.06      8.20  ...      1.21      1.34      2.43   \n",
      "\n",
      "         prob10    prob11    prob12    prob13    prob14    prob15    prob16  \n",
      "count 286100.00 286100.00 286100.00 286100.00 286100.00 286100.00 286100.00  \n",
      "mean       0.30      0.09      0.09      0.18      0.18      0.17      0.18  \n",
      "std        0.19      0.05      0.05      0.10      0.10      0.11      0.11  \n",
      "min        0.00      0.00      0.00      0.00      0.00      0.00      0.00  \n",
      "25%        0.15      0.05      0.06      0.09      0.11      0.07      0.09  \n",
      "50%        0.29      0.09      0.09      0.17      0.18      0.16      0.17  \n",
      "75%        0.41      0.12      0.12      0.24      0.25      0.25      0.25  \n",
      "max        1.89      0.52      0.43      0.79      0.87      0.65      0.80  \n",
      "\n",
      "[8 rows x 38 columns]\n",
      "       trousers_Ax_g  trousers_Ay_g  trousers_Az_g  back_Ax_g  back_Ay_g  \\\n",
      "count      286100.00      286100.00      286100.00  284600.00  284600.00   \n",
      "mean            1.88           0.11          -0.07       1.41      -0.48   \n",
      "std             0.42           0.36           0.62       0.70       0.69   \n",
      "min            -3.38          -3.59          -3.64      -2.69      -4.24   \n",
      "25%             1.77          -0.10          -0.54       1.16      -0.97   \n",
      "50%             1.90           0.11          -0.08       1.60      -0.59   \n",
      "75%             1.99           0.33           0.39       1.83      -0.11   \n",
      "max             4.78           3.33           4.07       4.51       3.20   \n",
      "\n",
      "       back_Az_g  hand_Ax_g  hand_Ay_g  hand_Az_g   subject  activity  \n",
      "count  284600.00  284600.00  284600.00  284600.00 286100.00 286100.00  \n",
      "mean       -0.01       1.24      -0.56      -0.05      7.01      7.99  \n",
      "std         1.07       1.13       0.59       0.92      3.75      4.33  \n",
      "min        -4.14      -3.08      -4.63      -4.23      1.00      1.00  \n",
      "25%        -0.89       1.02      -0.92      -0.64      4.00      4.00  \n",
      "50%        -0.21       1.68      -0.54      -0.07      7.00      8.00  \n",
      "75%         0.93       1.93      -0.19       0.56     10.00     12.00  \n",
      "max         4.36       4.74       4.11       4.01     13.00     15.00  \n"
     ]
    }
   ],
   "source": [
    "print(keypoint_data.shape)\n",
    "print(imu_data.shape)\n",
    "# check if the index for keypoint data and imu data are the same\n",
    "print(keypoint_data.index)\n",
    "print(imu_data.index)\n",
    "# check if the imu and keypoint have the same subject and activity at every row, count number of false\n",
    "print((keypoint_data['subject'] == imu_data['subject']).value_counts())\n",
    "\n",
    "print(keypoint_data['subject'].loc[0])\n",
    "print(imu_data['subject'].loc[0])\n",
    "print(keypoint_data.describe())\n",
    "print(imu_data.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:31.972389Z",
     "end_time": "2024-03-19T14:58:32.737685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1D CNN Layers, with 5 filters\n",
    "            nn.Conv2d(1, 5, (3, 1), stride=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            # output is 17 x 5 x 36\n",
    "            # flatten to 17 x 180\n",
    "            Rearrange('b c h w -> b h (c w)'),\n",
    "            # FC\n",
    "            nn.Linear(180, 100),\n",
    "            nn.ReLU(),\n",
    "            # LSTM\n",
    "            nn.LSTM(100, 100, 1, batch_first=True),\n",
    "            # output is 17 x 100\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(100, 45),\n",
    "            nn.ReLU(),\n",
    "            # make 17 x 1 x 9\n",
    "            Rearrange('b h (c w) -> b c h w', c=5, w=9),\n",
    "            # 1D CNN Layers, with 5 filters\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 1, (3, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, h = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:32.758681Z",
     "end_time": "2024-03-19T14:58:32.774680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "class DataSet_VTT(Dataset):\n",
    "    def __init__(self, keypoint_data, imu_data, sliding_windows, flag='train'):\n",
    "        self.flag = flag\n",
    "        # if train use all data except for user 1\n",
    "        if self.flag == 'train':\n",
    "            self.keypoint_data = keypoint_data[keypoint_data['subject'] != 1]\n",
    "            self.imu_data = imu_data[imu_data['subject'] != 1]\n",
    "            self.sliding_windows_map = sliding_windows[sliding_windows['subject'] != 1]\n",
    "            # reset the index\n",
    "            self.sliding_windows_map = self.sliding_windows_map.reset_index(drop=True)\n",
    "        # if test use only user 1\n",
    "        elif self.flag == 'test':\n",
    "            self.keypoint_data = keypoint_data[keypoint_data['subject'] == 1]\n",
    "            self.imu_data = imu_data[imu_data['subject'] == 1]\n",
    "            self.sliding_windows_map = sliding_windows[sliding_windows['subject'] == 1]\n",
    "            # reset the index\n",
    "            self.sliding_windows_map = self.sliding_windows_map.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sliding_windows_map[\"start\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = self.sliding_windows_map[\"start\"][idx]\n",
    "        end = self.sliding_windows_map[\"end\"][idx]\n",
    "        user = self.sliding_windows_map[\"subject\"][idx]\n",
    "        activity = self.sliding_windows_map[\"activity\"][idx]\n",
    "        # get the keypoint data for user and activity between start and end\n",
    "        keypoint = self.keypoint_data[\n",
    "                       (self.keypoint_data['subject'] == user) & (self.keypoint_data['activity'] == activity)].loc[\n",
    "                   start:end]\n",
    "        # check if any nan values in keypoint\n",
    "        # print(np.isnan(keypoint).any())\n",
    "        keypoint = keypoint.drop(columns=['subject', 'activity'])\n",
    "        # expand dimensions to make it 4D\n",
    "        keypoint = np.expand_dims(keypoint, axis=0)\n",
    "        imu = self.imu_data[(self.imu_data['subject'] == user) & (self.imu_data['activity'] == activity)].loc[\n",
    "              start:end]\n",
    "        imu = imu.drop(columns=['subject', 'activity'])\n",
    "        # imu to numpy\n",
    "        imu = imu.to_numpy()\n",
    "\n",
    "        # check if any nan values in keypoint\n",
    "        # print(np.isnan(keypoint).any())\n",
    "        # print('----------------')\n",
    "        return keypoint, imu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:32.785682Z",
     "end_time": "2024-03-19T14:58:32.804684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# replace any nan value as the mean of the value before and after it\n",
    "keypoint_data = keypoint_data.fillna(keypoint_data.mean())\n",
    "imu_data = imu_data.fillna(imu_data.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:32.807682Z",
     "end_time": "2024-03-19T14:58:33.134601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x5          False\n",
      "y5          False\n",
      "x6          False\n",
      "y6          False\n",
      "x7          False\n",
      "y7          False\n",
      "x8          False\n",
      "y8          False\n",
      "x9          False\n",
      "y9          False\n",
      "x10         False\n",
      "y10         False\n",
      "x11         False\n",
      "y11         False\n",
      "x12         False\n",
      "y12         False\n",
      "x13         False\n",
      "y13         False\n",
      "x14         False\n",
      "y14         False\n",
      "x15         False\n",
      "y15         False\n",
      "x16         False\n",
      "y16         False\n",
      "activity    False\n",
      "subject     False\n",
      "prob5       False\n",
      "prob6       False\n",
      "prob7       False\n",
      "prob8       False\n",
      "prob9       False\n",
      "prob10      False\n",
      "prob11      False\n",
      "prob12      False\n",
      "prob13      False\n",
      "prob14      False\n",
      "prob15      False\n",
      "prob16      False\n",
      "dtype: bool\n",
      "trousers_Ax_g    False\n",
      "trousers_Ay_g    False\n",
      "trousers_Az_g    False\n",
      "back_Ax_g        False\n",
      "back_Ay_g        False\n",
      "back_Az_g        False\n",
      "hand_Ax_g        False\n",
      "hand_Ay_g        False\n",
      "hand_Az_g        False\n",
      "subject          False\n",
      "activity         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# check if any nan values in keypoint\n",
    "print(np.isnan(keypoint_data).any())\n",
    "print(np.isnan(imu_data).any())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:33.139610Z",
     "end_time": "2024-03-19T14:58:33.193769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "dataset_train = DataSet_VTT(keypoint_data, imu_data, sliding_windows, flag='train')\n",
    "dataset_test = DataSet_VTT(keypoint_data, imu_data, sliding_windows, flag='test')\n",
    "train_loader = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:09.024514Z",
     "end_time": "2024-03-19T15:00:09.134091Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = (25, 36)\n",
    "output_size = (25, 9)\n",
    "model = EncoderDecoder(input_size, output_size)\n",
    "model = model.double().cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:09.499574Z",
     "end_time": "2024-03-19T15:00:09.531580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 25, 36)\n",
      "(32, 1, 25, 36)\n",
      "tensor([[[[-1.0938e+00,  5.6767e-02, -5.4950e-01,  ...,  5.3953e-02,\n",
      "           -4.0240e-01, -1.0285e-01],\n",
      "          [-1.0938e+00, -3.4760e-01, -6.9826e-01,  ...,  4.6984e-01,\n",
      "            8.3003e-02,  4.0965e-01],\n",
      "          [-1.0401e+00, -3.5267e-01, -1.7939e-01,  ...,  6.4363e-01,\n",
      "           -5.4432e-02,  5.2749e-01],\n",
      "          ...,\n",
      "          [-1.0938e+00,  2.1561e-01,  7.8518e-01,  ...,  2.1747e+00,\n",
      "           -9.5683e-02,  1.1864e+00],\n",
      "          [ 3.4238e-01, -4.4306e-01, -3.1246e-01,  ..., -6.1757e-01,\n",
      "           -2.4586e-01, -3.7115e-01],\n",
      "          [-1.0938e+00, -1.0938e+00, -2.8140e-01,  ..., -3.2778e-01,\n",
      "           -8.4025e-01, -4.8197e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0938e+00,  4.4470e-02, -3.9756e-01,  ...,  3.5513e-02,\n",
      "           -2.6956e-01, -7.4360e-02],\n",
      "          [-1.0938e+00, -4.2346e-01, -1.7698e-01,  ...,  4.3826e-01,\n",
      "            3.5607e-02,  6.7274e-01],\n",
      "          [-9.6835e-01, -2.0615e-01, -2.9252e-02,  ...,  6.5793e-01,\n",
      "            6.5318e-01,  3.6407e-01],\n",
      "          ...,\n",
      "          [ 1.2482e-02,  2.0548e+00,  1.3790e-01,  ...,  2.1028e+00,\n",
      "           -1.0938e+00,  1.1013e+00],\n",
      "          [-6.2983e-01, -3.5444e-01,  2.2346e-01,  ..., -5.7061e-01,\n",
      "           -5.8621e-01,  2.3614e-01],\n",
      "          [-5.6281e-01, -6.9137e-01, -7.6166e-01,  ..., -3.2911e-01,\n",
      "           -1.0938e+00, -8.3999e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0938e+00,  6.9117e-02, -4.2314e-01,  ...,  5.3953e-02,\n",
      "           -6.6648e-01, -5.5486e-02],\n",
      "          [-1.0938e+00, -7.1635e-02, -1.1636e-01,  ...,  4.6984e-01,\n",
      "           -1.4739e-01,  1.6407e-01],\n",
      "          [-9.7574e-01, -9.9843e-03,  7.2478e-01,  ...,  6.4363e-01,\n",
      "            3.5205e-01,  8.2574e-01],\n",
      "          ...,\n",
      "          [-5.9512e-01,  1.2742e+00, -1.0938e+00,  ...,  2.0400e+00,\n",
      "           -8.0263e-01,  1.4617e+00],\n",
      "          [ 1.8444e-01, -4.1421e-01, -1.3063e-01,  ..., -5.1358e-01,\n",
      "            1.6060e-01,  1.1999e-03],\n",
      "          [-4.8926e-01, -1.0938e+00,  5.6437e-02,  ..., -2.6599e-01,\n",
      "           -1.0938e+00, -9.4375e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2884e-03, -2.5930e-02, -3.1982e-01,  ...,  5.3953e-02,\n",
      "           -1.0329e-01, -2.0346e-01],\n",
      "          [ 2.4857e-01, -5.3416e-01, -6.2070e-02,  ...,  4.6984e-01,\n",
      "           -2.7954e-01,  5.1458e-01],\n",
      "          [ 7.1593e-01, -7.0756e-01,  8.4554e-01,  ...,  6.4363e-01,\n",
      "            8.8429e-02,  7.9534e-01],\n",
      "          ...,\n",
      "          [ 6.7255e-01,  6.9959e-01,  1.0730e+00,  ...,  2.1747e+00,\n",
      "           -1.0938e+00,  1.8233e+00],\n",
      "          [-7.9560e-01, -3.9897e-01, -9.8931e-01,  ..., -6.1757e-01,\n",
      "           -1.1131e-01,  5.8192e-02],\n",
      "          [-1.8982e-01, -1.0938e+00, -1.8246e-02,  ..., -3.2778e-01,\n",
      "           -1.0938e+00, -4.9206e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0938e+00,  6.9800e-02, -1.2261e-01,  ...,  3.5362e-02,\n",
      "           -5.6043e-01, -2.9146e-01],\n",
      "          [-1.0938e+00, -4.5665e-01,  4.0540e-01,  ...,  4.3802e-01,\n",
      "           -9.5538e-02,  6.9204e-01],\n",
      "          [ 1.2821e-01, -6.0498e-01,  7.2375e-01,  ...,  6.5817e-01,\n",
      "           -6.8120e-01,  7.0233e-01],\n",
      "          ...,\n",
      "          [-8.5264e-01,  1.7550e-01,  6.0515e-01,  ...,  2.1747e+00,\n",
      "            1.4214e-01,  1.2993e+00],\n",
      "          [ 4.5143e-01, -7.7978e-01, -7.7600e-02,  ..., -6.1757e-01,\n",
      "           -6.1683e-02, -1.0889e-03],\n",
      "          [-9.2476e-01, -1.0938e+00, -2.3718e-01,  ..., -3.2778e-01,\n",
      "           -1.0938e+00, -4.3021e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5604e-01,  6.5240e-02, -1.0938e+00,  ...,  4.1776e-02,\n",
      "           -4.5725e-01, -6.5514e-02],\n",
      "          [ 1.5036e-01, -4.4782e-01, -1.0938e+00,  ...,  4.4846e-01,\n",
      "           -1.6039e-01,  4.0502e-01],\n",
      "          [ 7.9359e-01, -6.0568e-01, -7.8890e-01,  ...,  6.4980e-01,\n",
      "           -1.0938e+00,  7.6034e-01],\n",
      "          ...,\n",
      "          [ 9.3745e-02, -5.3572e-01,  2.9569e-01,  ...,  2.1747e+00,\n",
      "           -5.1093e-01,  2.1177e+00],\n",
      "          [-6.2089e-01, -4.9464e-01, -4.6675e-01,  ..., -6.1757e-01,\n",
      "           -3.0234e-02, -4.5455e-01],\n",
      "          [-7.8886e-01, -1.0938e+00, -1.0225e-01,  ..., -3.2778e-01,\n",
      "           -1.0938e+00, -3.7454e-01]]]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CudnnBatchNormBackward0>)\n",
      "torch.Size([32, 25, 9])\n"
     ]
    }
   ],
   "source": [
    "# test model input output size by giving random input\n",
    "test = np.random.rand(32, 25, 36)\n",
    "print(test.shape)\n",
    "test = np.expand_dims(test, axis=1)\n",
    "print(test.shape)\n",
    "test = torch.tensor(test, dtype=torch.double).to(device)\n",
    "# print(test)\n",
    "y = model(test)\n",
    "# remove the first dimension\n",
    "print(y)\n",
    "y = y.squeeze(1)\n",
    "# print the output size\n",
    "print(y.shape)\n",
    "# print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:13.655904Z",
     "end_time": "2024-03-19T15:00:13.972795Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x144b145d2e0>"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:16.629781Z",
     "end_time": "2024-03-19T15:00:16.645827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 0, Loss: 32.560827343581636\n",
      "Epoch: 0, Loss: 3.6851020641451164\n",
      "Epoch: 0, Loss: 2.6469098468286534\n",
      "Epoch: 0, Loss: -7.160711051678369\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    for i, data in enumerate(train_loader):\n",
    "        keypoint, imu = data\n",
    "        keypoint = keypoint.double().to(device)\n",
    "        # check if keypoint has any nan values\n",
    "        # print(torch.isnan(keypoint).any())\n",
    "        imu = imu.double().to(device)\n",
    "        output = model(keypoint)\n",
    "        output = output.squeeze(1)\n",
    "        loss = criterion(output, imu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:17.708378Z",
     "end_time": "2024-03-19T15:01:27.479770Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(imu_data[(imu_data['subject'] == 7) & (imu_data['activity'] == 7)].index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T10:26:07.338582Z",
     "end_time": "2024-03-19T10:26:07.382075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T10:26:07.355581Z",
     "end_time": "2024-03-19T10:26:07.382829Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T10:26:07.369582Z",
     "end_time": "2024-03-19T10:26:07.404913Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
