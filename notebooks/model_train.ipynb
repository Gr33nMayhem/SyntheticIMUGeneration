{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter, resample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy import misc\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T09:29:36.061572Z",
     "end_time": "2024-03-28T09:29:58.602524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if cuda is available\n",
    "print(torch.cuda.is_available())\n",
    "torch.autograd.set_detect_anomaly(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T09:29:58.604529Z",
     "end_time": "2024-03-28T09:29:58.695477Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = '../data/VTT_ConIot_Dataset'\n",
    "IMU_path = data_path + '/IMU'\n",
    "Keypoint_path = data_path + '/Keypoint'\n",
    "activities = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "users = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T09:29:58.698477Z",
     "end_time": "2024-03-28T09:29:58.710037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T10:07:50.265687Z",
     "end_time": "2024-03-28T10:07:50.289234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def create_keypoint_and_imu_data(subject, activity):\n",
    "    '''\n",
    "    This function reads the keypoint and imu data for a given subject and activity\n",
    "    :param subject:\n",
    "    :param activity:\n",
    "    :return:\n",
    "    '''\n",
    "    # check if file exists\n",
    "    if not os.path.exists(Keypoint_path + f'/Subject_{subject:02d}_Task_{activity}.m2ts_keyPoints.csv'):\n",
    "        print(f'Keypoint file for Subject_{subject:02d}_Task_{activity} does not exist')\n",
    "        # return two empty dataframes\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    keypoint_data = pd.read_csv(Keypoint_path + f'/Subject_{subject:02d}_Task_{activity}.m2ts_keyPoints.csv')\n",
    "    imu_data = pd.read_csv(IMU_path + f'/activity_{activity}_user_{subject}_combined.csv')\n",
    "    # only keep the columns in imu data that are of accelerometer, i.e. that have _A in the name\n",
    "    imu_data = imu_data[[col for col in imu_data.columns if '_A' in col]]\n",
    "    # remove frame_number and timestamp columns from keypoint data\n",
    "    keypoint_data = keypoint_data.drop(columns=['frame_number', 'timestamp'])\n",
    "    keypoint_data['subject'] = subject\n",
    "    keypoint_data['activity'] = activity\n",
    "    imu_data['subject'] = subject\n",
    "    imu_data['activity'] = activity\n",
    "    # make sure subject and activity are of type float\n",
    "    keypoint_data['subject'] = keypoint_data['subject'].astype(float)\n",
    "    keypoint_data['activity'] = keypoint_data['activity'].astype(float)\n",
    "    imu_data['subject'] = imu_data['subject'].astype(float)\n",
    "    imu_data['activity'] = imu_data['activity'].astype(float)\n",
    "    return keypoint_data, imu_data\n",
    "\n",
    "\n",
    "def create_relative_keypoints(df_keypoints, relative_to='head'):\n",
    "    '''\n",
    "    \"keypoints\": [\n",
    "            \"nose\",\"left_eye\",\"right_eye\",\"left_ear\",\"right_ear\",\n",
    "            \"left_shoulder\",\"right_shoulder\",\"left_elbow\",\"right_elbow\",\n",
    "            \"left_wrist\",\"right_wrist\",\"left_hip\",\"right_hip\",\n",
    "            \"left_knee\",\"right_knee\",\"left_ankle\",\"right_ankle\"\n",
    "        ],\n",
    "    \"corresponding points\":[\n",
    "            \"0\", \"1\", \"2\", \"3\", \"4\",\n",
    "            \"5\", \"6\", \"7\", \"8\",\n",
    "            \"9\", \"10\", \"11\", \"12\",\n",
    "            \"13\", \"14\", \"15\", \"16\"\n",
    "        ]\n",
    "    There are 17 points with each point having their x, y and confidence values\n",
    "    :param df_keypoints:\n",
    "    :param relative_to: Can be 'head' or 'shoulder'\n",
    "    :param relative_motion:\n",
    "    :return:\n",
    "    '''\n",
    "    # drop the column \"detection_score\" as they are all high\n",
    "    df_keypoints = df_keypoints.drop(columns=['detection_score'])\n",
    "\n",
    "    if relative_to == 'head':\n",
    "        '''create a average column of the x and y of nose, left eye, right eye, left ear and right ear\n",
    "           and call it x_head, y_head, prob_headwhere the columns for x and y are labelled as\n",
    "           x0,y0,prob0,x1,y1,prob1,....,x16,y16,prob16\n",
    "           get the x and y values for the nose, left eye, right eye, left ear and right ear'''\n",
    "        x_root = (df_keypoints['x0'] + df_keypoints['x1'] + df_keypoints['x2'] + df_keypoints['x3'] +\n",
    "                  df_keypoints['x4']) / 5\n",
    "        y_root = (df_keypoints['y0'] + df_keypoints['y1'] + df_keypoints['y2'] + df_keypoints['y3'] +\n",
    "                  df_keypoints['y4']) / 5\n",
    "\n",
    "        # set prob_head as the maximum of the probabilities of the nose, left eye, right eye, left ear and right ear\n",
    "        prob_root = df_keypoints[['prob0', 'prob1', 'prob2', 'prob3', 'prob4']].max(axis=1)\n",
    "    else:\n",
    "        ''' Use the mean of the left and the right shoulder as the root point'''\n",
    "        x_root = (df_keypoints['x5'] + df_keypoints['x6']) / 2\n",
    "        y_root = (df_keypoints['y5'] + df_keypoints['y6']) / 2\n",
    "        prob_root = (df_keypoints['prob5'] + df_keypoints['prob6']) / 2\n",
    "\n",
    "    # add the columns to the dataframe\n",
    "    df_keypoints['x_root'] = x_root\n",
    "    df_keypoints['y_root'] = y_root\n",
    "    df_keypoints['prob_root'] = prob_root\n",
    "\n",
    "    # drop the columns for the nose, left eye, right eye, left ear and right ear\n",
    "    df_keypoints = df_keypoints.drop(columns=['x0', 'y0', 'prob0', 'x1', 'y1', 'prob1', 'x2', 'y2', 'prob2',\n",
    "                                              'x3', 'y3', 'prob3', 'x4', 'y4', 'prob4'])\n",
    "\n",
    "    # convert the x and y values to be relative to the head\n",
    "    for i in range(5, 17):\n",
    "        df_keypoints[f'x{i}'] = df_keypoints[f'x{i}'] - df_keypoints['x_root']\n",
    "        df_keypoints[f'y{i}'] = df_keypoints[f'y{i}'] - df_keypoints['y_root']\n",
    "\n",
    "    # drop the columns for the x and y values of the head\n",
    "    df_keypoints = df_keypoints.drop(columns=['x_root', 'y_root', 'prob_root'])\n",
    "\n",
    "    return df_keypoints\n",
    "\n",
    "\n",
    "def create_delta_keypoints(df_keypoints):\n",
    "    '''\n",
    "    This function creates the delta keypoints from the keypoint data\n",
    "    :param df_keypoints:\n",
    "    :return:\n",
    "    '''\n",
    "    # get the columns that have x and y values\n",
    "    x_cols = [col for col in df_keypoints.columns if 'x' in col]\n",
    "    y_cols = [col for col in df_keypoints.columns if 'y' in col]\n",
    "    # get the columns that have prob values\n",
    "    prob_cols = [col for col in df_keypoints.columns if 'prob' in col]\n",
    "\n",
    "    final_keypoints = pd.DataFrame()\n",
    "    # create a new dataframe to store the delta values\n",
    "    delta_keypoints = pd.DataFrame()\n",
    "    # for x and y cols, reset their values as the difference between the current value and the previous value\n",
    "    for x_col, y_col in zip(x_cols, y_cols):\n",
    "        delta_keypoints[f'delta_{x_col}'] = df_keypoints[x_col].diff()\n",
    "        delta_keypoints[f'delta_{y_col}'] = df_keypoints[y_col].diff()\n",
    "\n",
    "    # replace the nan values with 0\n",
    "\n",
    "    delta_keypoints = delta_keypoints.fillna(0.5)\n",
    "\n",
    "    # recreate the dataframe in columns format x , y, prob\n",
    "    for x_col, y_col, prob_col in zip(x_cols, y_cols, prob_cols):\n",
    "        final_keypoints[x_col] = delta_keypoints[f'delta_{x_col}']\n",
    "        final_keypoints[y_col] = delta_keypoints[f'delta_{y_col}']\n",
    "        final_keypoints[prob_col] = df_keypoints[prob_col]\n",
    "\n",
    "    # add the activity and subject columns back\n",
    "    final_keypoints['activity'] = df_keypoints['activity']\n",
    "    final_keypoints['subject'] = df_keypoints['subject']\n",
    "\n",
    "    return final_keypoints\n",
    "\n",
    "\n",
    "def processed_data():\n",
    "    '''\n",
    "    This function reads the keypoint and imu data for all subjects and activities. Then processes it.\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    # create a dataframe with all the keypoint and imu data\n",
    "    full_keypoint_data = pd.DataFrame()\n",
    "    full_imu_data = pd.DataFrame()\n",
    "    for activity in activities:\n",
    "        for user in users:\n",
    "            keypoint_data, imu_data = create_keypoint_and_imu_data(user, activity)\n",
    "            full_keypoint_data = pd.concat([full_keypoint_data, keypoint_data])\n",
    "            full_imu_data = pd.concat([full_imu_data, imu_data])\n",
    "\n",
    "    ''' Resampling and Cropping of Data Started'''\n",
    "    # pre-pocess by removing the extra time stamps fom either keypoint or imu data\n",
    "    # per participant and activity pair there should be 4x the number of imu data points as keypoint data points\n",
    "    cropped_keypoint_data = pd.DataFrame()\n",
    "    cropped_imu_data = pd.DataFrame()\n",
    "    for activity in activities:\n",
    "        for user in users:\n",
    "            # print shape of keypoint and imu data\n",
    "            keypoint_data = full_keypoint_data[\n",
    "                (full_keypoint_data['subject'] == user) & (full_keypoint_data['activity'] == activity)]\n",
    "            imu_data = full_imu_data[(full_imu_data['subject'] == user) & (full_imu_data['activity'] == activity)]\n",
    "\n",
    "            # if either of the data is empty, skip\n",
    "            if keypoint_data.shape[0] == 0 or imu_data.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            if keypoint_data.shape[0] * 4 > imu_data.shape[0]:\n",
    "                # remove the extra keypoint data\n",
    "                keypoint_data = keypoint_data.iloc[:imu_data.shape[0] // 4]\n",
    "            else:\n",
    "                # remove the extra imu data\n",
    "                imu_data = imu_data.iloc[:keypoint_data.shape[0] * 4]\n",
    "            # remove keypoint values such that keypoint data is multiple of 25\n",
    "            keypoint_data = keypoint_data.iloc[:keypoint_data.shape[0] // 25 * 25]\n",
    "\n",
    "            # remove imu values such that imu data is multiple of 100\n",
    "            imu_data = imu_data.iloc[:imu_data.shape[0] // 100 * 100]\n",
    "\n",
    "            # make copy of the columns subject and activity before dropping\n",
    "            subject_col = imu_data['subject']\n",
    "            activity_col = imu_data['activity']\n",
    "            imu_data = imu_data.drop(columns=['subject', 'activity'])\n",
    "            # resample the imu data to be the same length as the keypoint data\n",
    "            imu_resampled = resample(imu_data, keypoint_data.shape[0])\n",
    "            # create a pd dataframe from the resampled data using the columns in imu_data\n",
    "            imu_data = pd.DataFrame(imu_resampled, columns=imu_data.columns)\n",
    "            # add the subject and activity columns back\n",
    "            imu_data['subject'] = subject_col\n",
    "            imu_data['activity'] = activity_col\n",
    "\n",
    "            cropped_keypoint_data = pd.concat([cropped_keypoint_data, keypoint_data])\n",
    "            cropped_imu_data = pd.concat([cropped_imu_data, imu_data])\n",
    "\n",
    "    # reset the index keypoint\n",
    "    cropped_keypoint_data = cropped_keypoint_data.reset_index(drop=True)\n",
    "    ''' Resampling and Cropping of Data Completed'''\n",
    "\n",
    "    ''' Relative Keypoints and Sliding Windows Started'''\n",
    "    # preprocess the keypoints for each point of interest from pose estimation\n",
    "    cropped_keypoint_data = create_relative_keypoints(cropped_keypoint_data, relative_to='shoulder')\n",
    "\n",
    "    # reset the index for imu\n",
    "    cropped_imu_data = cropped_imu_data.reset_index(drop=True)\n",
    "    ''' Relative Keypoints and Sliding Windows Completed'''\n",
    "\n",
    "    ''' Create Delta KeyPoints Started'''\n",
    "    cropped_keypoint_data = create_delta_keypoints(cropped_keypoint_data)\n",
    "    ''' Create Delta KeyPoints Completed'''\n",
    "\n",
    "    ''' Sliding Windows Started'''\n",
    "    # create a new df between 25 key-points and 100 IMU data points for each activity and user\n",
    "    # with columns start, end, subject, activity\n",
    "    sliding_windows = pd.DataFrame(columns=['start', 'end', 'subject', 'activity'])\n",
    "\n",
    "    for activity in activities:\n",
    "        for user in users:\n",
    "            # preserve the index\n",
    "            keypoint_data = cropped_keypoint_data[\n",
    "                (cropped_keypoint_data['subject'] == user) & (cropped_keypoint_data['activity'] == activity)]\n",
    "            # if either of the data is empty, skip\n",
    "            if keypoint_data.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            # split the data into windows of 25\n",
    "            for i in range(0, keypoint_data.shape[0], 25):\n",
    "                # check if the window has 25 elements\n",
    "                if i + 25 > keypoint_data.shape[0]:\n",
    "                    continue\n",
    "                # get the start and end index of the window in cropped_keypoint_data\n",
    "                start = keypoint_data.index[i]\n",
    "                end = keypoint_data.index[i + 25 - 1]\n",
    "                # concat to the sliding_windows dataframe\n",
    "                sliding_windows = pd.concat([sliding_windows, pd.DataFrame(\n",
    "                    {'start': [start], 'end': [end], 'subject': [user], 'activity': [activity]})])\n",
    "\n",
    "    sliding_windows = sliding_windows.reset_index(drop=True)\n",
    "    ''' Sliding Windows Completed'''\n",
    "\n",
    "    ''' Normalize Data Started'''\n",
    "    # normalize the keypoint data\n",
    "    # create a copy of column activity and subject before dropping\n",
    "    activity = cropped_keypoint_data['activity']\n",
    "    subject = cropped_keypoint_data['subject']\n",
    "    # create a copy of all columns starting with prob\n",
    "    prob_cols = cropped_keypoint_data.filter(regex='prob').copy()\n",
    "    # drop the columns activity, subject and all columns starting with prob\n",
    "    cropped_keypoint_data = cropped_keypoint_data.drop(columns=['activity', 'subject'])\n",
    "    cropped_keypoint_data = cropped_keypoint_data.drop(columns=cropped_keypoint_data.filter(regex='prob').columns)\n",
    "    # Do a normalization\n",
    "    scaler = StandardScaler()\n",
    "    cropped_keypoint_data = pd.DataFrame(scaler.fit_transform(cropped_keypoint_data),\n",
    "                                         columns=cropped_keypoint_data.columns)\n",
    "    # add the columns activity and subject back\n",
    "    cropped_keypoint_data['activity'] = activity\n",
    "    cropped_keypoint_data['subject'] = subject\n",
    "    # add the columns starting with prob back\n",
    "    cropped_keypoint_data = pd.concat([cropped_keypoint_data, prob_cols], axis=1)\n",
    "    ''' Normalize Data Completed'''\n",
    "\n",
    "    return cropped_keypoint_data, cropped_imu_data, sliding_windows\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T11:42:19.644497Z",
     "end_time": "2024-03-28T11:42:19.659274Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoint file for Subject_06_Task_11 does not exist\n",
      "        delta_x5  delta_y5  delta_x6  delta_y6  delta_x7  delta_y7  delta_x8  \\\n",
      "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "1          -2.09     -0.72      2.09      0.72     -7.79      0.78      0.61   \n",
      "2          -1.46      0.00      1.46     -0.00     -4.34      7.09      1.48   \n",
      "3           5.97     -3.60     -5.97      3.60      6.04     -7.87      6.82   \n",
      "4           0.72     -0.72     -0.72      0.72    -18.00     10.79     -2.16   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "286095     -6.41     -0.00      6.41      0.00     13.69     18.52     25.07   \n",
      "286096     -0.00     -2.15      0.00      2.15     -0.03      2.39     -0.03   \n",
      "286097     -2.15      4.31      2.15     -4.31     -3.58     -0.11    -12.19   \n",
      "286098      1.43     -1.43     -1.43      1.43     -1.60      0.18     -2.88   \n",
      "286099     -5.03    -13.66      5.03     13.66     -3.39    -23.73     -2.14   \n",
      "\n",
      "        delta_y8  delta_x9  delta_y9  ...  delta_x12  delta_y12  delta_x13  \\\n",
      "0            NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
      "1         -10.73     -6.34      6.58  ...      -0.76     -10.66       3.61   \n",
      "2           2.76     -1.48     -3.07  ...       1.46      -1.67      17.19   \n",
      "3           6.52     -1.09      2.24  ...       2.72       9.45      10.26   \n",
      "4           0.72    -36.71      7.91  ...      -2.16       2.16      -2.16   \n",
      "...          ...       ...       ...  ...        ...        ...        ...   \n",
      "286095     30.01     13.41     14.23  ...      14.98      15.57      17.97   \n",
      "286096      3.82      0.03      2.36  ...       1.43      -0.36      -0.03   \n",
      "286097     -8.72     -2.15      1.34  ...      -0.72       5.59      -3.58   \n",
      "286098      0.17     -2.62      1.60  ...      -2.85       1.72      -1.60   \n",
      "286099    -19.41     -2.47    -22.29  ...      -5.05     -19.41      -7.70   \n",
      "\n",
      "        delta_y13  delta_x14  delta_y14  delta_x15  delta_y15  delta_x16  \\\n",
      "0             NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1          -16.32       2.10     -16.32     -10.76     -20.55       0.63   \n",
      "2          -21.97      17.23      -9.03       1.44     -23.56       1.47   \n",
      "3          -14.95      11.41     -13.51       4.28     -19.20       1.14   \n",
      "4           -6.48      -7.92       0.72      -5.04      -6.48      -3.60   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "286095     -10.37      15.10     -10.37      13.69     -10.37      13.69   \n",
      "286096       5.55      -1.46       5.55      -0.03       5.55      -0.03   \n",
      "286097       6.95      -2.15       6.95      -3.58       6.95      -3.58   \n",
      "286098       1.85      -2.99       1.85      -1.60       1.85      -1.60   \n",
      "286099      -2.16     -16.38      13.66      -3.39     -26.60      -3.39   \n",
      "\n",
      "        delta_y16  \n",
      "0             NaN  \n",
      "1          -26.31  \n",
      "2          -16.37  \n",
      "3          -17.76  \n",
      "4           -6.48  \n",
      "...           ...  \n",
      "286095     -10.37  \n",
      "286096       5.55  \n",
      "286097       6.95  \n",
      "286098       1.85  \n",
      "286099     -28.04  \n",
      "\n",
      "[286100 rows x 24 columns]\n",
      "          x5     y5  prob5    x6    y6  prob6     x7     y7  prob7     x8  \\\n",
      "0       0.50   0.50   0.29  0.50  0.50   0.18   0.50   0.50   0.16   0.50   \n",
      "1      -2.09  -0.72   0.27  2.09  0.72   0.18  -7.79   0.78   0.11   0.61   \n",
      "2      -1.46   0.00   0.19  1.46 -0.00   0.12  -4.34   7.09   0.08   1.48   \n",
      "3       5.97  -3.60   0.15 -5.97  3.60   0.11   6.04  -7.87   0.10   6.82   \n",
      "4       0.72  -0.72   0.18 -0.72  0.72   0.09 -18.00  10.79   0.08  -2.16   \n",
      "...      ...    ...    ...   ...   ...    ...    ...    ...    ...    ...   \n",
      "286095 -6.41  -0.00   0.02  6.41  0.00   0.02  13.69  18.52   0.11  25.07   \n",
      "286096 -0.00  -2.15   0.02  0.00  2.15   0.02  -0.03   2.39   0.09  -0.03   \n",
      "286097 -2.15   4.31   0.02  2.15 -4.31   0.01  -3.58  -0.11   0.10 -12.19   \n",
      "286098  1.43  -1.43   0.01 -1.43  1.43   0.01  -1.60   0.18   0.07  -2.88   \n",
      "286099 -5.03 -13.66   0.01  5.03 13.66   0.01  -3.39 -23.73   0.09  -2.14   \n",
      "\n",
      "        ...    y14  prob14    x15    y15  prob15   x16    y16  prob16  \\\n",
      "0       ...   0.50    0.12   0.50   0.50    0.22  0.50   0.50    0.19   \n",
      "1       ... -16.32    0.12 -10.76 -20.55    0.16  0.63 -26.31    0.21   \n",
      "2       ...  -9.03    0.16   1.44 -23.56    0.26  1.47 -16.37    0.27   \n",
      "3       ... -13.51    0.13   4.28 -19.20    0.29  1.14 -17.76    0.27   \n",
      "4       ...   0.72    0.13  -5.04  -6.48    0.26 -3.60  -6.48    0.20   \n",
      "...     ...    ...     ...    ...    ...     ...   ...    ...     ...   \n",
      "286095  ... -10.37    0.04  13.69 -10.37    0.05 13.69 -10.37    0.03   \n",
      "286096  ...   5.55    0.04  -0.03   5.55    0.04 -0.03   5.55    0.03   \n",
      "286097  ...   6.95    0.03  -3.58   6.95    0.04 -3.58   6.95    0.03   \n",
      "286098  ...   1.85    0.03  -1.60   1.85    0.03 -1.60   1.85    0.02   \n",
      "286099  ...  13.66    0.02  -3.39 -26.60    0.03 -3.39 -28.04    0.02   \n",
      "\n",
      "        activity  subject  \n",
      "0           1.00     1.00  \n",
      "1           1.00     1.00  \n",
      "2           1.00     1.00  \n",
      "3           1.00     1.00  \n",
      "4           1.00     1.00  \n",
      "...          ...      ...  \n",
      "286095     15.00    13.00  \n",
      "286096     15.00    13.00  \n",
      "286097     15.00    13.00  \n",
      "286098     15.00    13.00  \n",
      "286099     15.00    13.00  \n",
      "\n",
      "[286100 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "keypoint_data, imu_data, sliding_windows = processed_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T11:42:20.017108Z",
     "end_time": "2024-03-28T11:42:57.023424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(keypoint_data.shape)\n",
    "print(imu_data.shape)\n",
    "# check if the index for keypoint data and imu data are the same\n",
    "print(keypoint_data.index)\n",
    "print(imu_data.index)\n",
    "# check if the imu and keypoint have the same subject and activity at every row, count number of false\n",
    "print((keypoint_data['subject'] == imu_data['subject']).value_counts())\n",
    "\n",
    "print(keypoint_data['subject'].loc[0])\n",
    "print(imu_data['subject'].loc[0])\n",
    "print(keypoint_data.describe())\n",
    "print(imu_data.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T09:30:49.334077Z",
     "end_time": "2024-03-28T09:30:49.998241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1D CNN Layers, with 5 filters\n",
    "            nn.Conv2d(1, 5, (3, 1), stride=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            # output is 17 x 5 x 36\n",
    "            # flatten to 17 x 180\n",
    "            Rearrange('b c h w -> b h (c w)'),\n",
    "            # FC\n",
    "            nn.Linear(180, 100),\n",
    "            nn.ReLU(),\n",
    "            # LSTM\n",
    "            nn.LSTM(100, 100, 1, batch_first=True),\n",
    "            # output is 17 x 100\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(100, 45),\n",
    "            nn.ReLU(),\n",
    "            # make 17 x 1 x 9\n",
    "            Rearrange('b h (c w) -> b c h w', c=5, w=9),\n",
    "            # 1D CNN Layers, with 5 filters\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 5, (3, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.Conv2d(5, 1, (3, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, h = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:32.758681Z",
     "end_time": "2024-03-19T14:58:32.774680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DataSet_VTT(Dataset):\n",
    "    def __init__(self, keypoint_data, imu_data, sliding_windows, flag='train'):\n",
    "        self.flag = flag\n",
    "        # if train use all data except for user 1\n",
    "        if self.flag == 'train':\n",
    "            self.keypoint_data = keypoint_data[keypoint_data['subject'] != 1]\n",
    "            self.imu_data = imu_data[imu_data['subject'] != 1]\n",
    "            self.sliding_windows_map = sliding_windows[sliding_windows['subject'] != 1]\n",
    "            # reset the index\n",
    "            self.sliding_windows_map = self.sliding_windows_map.reset_index(drop=True)\n",
    "        # if test use only user 1\n",
    "        elif self.flag == 'test':\n",
    "            self.keypoint_data = keypoint_data[keypoint_data['subject'] == 1]\n",
    "            self.imu_data = imu_data[imu_data['subject'] == 1]\n",
    "            self.sliding_windows_map = sliding_windows[sliding_windows['subject'] == 1]\n",
    "            # reset the index\n",
    "            self.sliding_windows_map = self.sliding_windows_map.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sliding_windows_map[\"start\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = self.sliding_windows_map[\"start\"][idx]\n",
    "        end = self.sliding_windows_map[\"end\"][idx]\n",
    "        user = self.sliding_windows_map[\"subject\"][idx]\n",
    "        activity = self.sliding_windows_map[\"activity\"][idx]\n",
    "        # get the keypoint data for user and activity between start and end\n",
    "        keypoint = self.keypoint_data[\n",
    "                       (self.keypoint_data['subject'] == user) & (self.keypoint_data['activity'] == activity)].loc[\n",
    "                   start:end]\n",
    "        # check if any nan values in keypoint\n",
    "        # print(np.isnan(keypoint).any())\n",
    "        keypoint = keypoint.drop(columns=['subject', 'activity'])\n",
    "        # expand dimensions to make it 4D\n",
    "        keypoint = np.expand_dims(keypoint, axis=0)\n",
    "        imu = self.imu_data[(self.imu_data['subject'] == user) & (self.imu_data['activity'] == activity)].loc[\n",
    "              start:end]\n",
    "        imu = imu.drop(columns=['subject', 'activity'])\n",
    "        # imu to numpy\n",
    "        imu = imu.to_numpy()\n",
    "\n",
    "        # check if any nan values in keypoint\n",
    "        # print(np.isnan(keypoint).any())\n",
    "        # print('----------------')\n",
    "        return keypoint, imu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:32.785682Z",
     "end_time": "2024-03-19T14:58:32.804684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# replace any nan value as the mean of the value before and after it\n",
    "keypoint_data = keypoint_data.fillna(keypoint_data.mean())\n",
    "imu_data = imu_data.fillna(imu_data.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:32.807682Z",
     "end_time": "2024-03-19T14:58:33.134601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if any nan values in keypoint\n",
    "print(np.isnan(keypoint_data).any())\n",
    "print(np.isnan(imu_data).any())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T14:58:33.139610Z",
     "end_time": "2024-03-19T14:58:33.193769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_train = DataSet_VTT(keypoint_data, imu_data, sliding_windows, flag='train')\n",
    "dataset_test = DataSet_VTT(keypoint_data, imu_data, sliding_windows, flag='test')\n",
    "train_loader = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:09.024514Z",
     "end_time": "2024-03-19T15:00:09.134091Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = (25, 36)\n",
    "output_size = (25, 9)\n",
    "model = EncoderDecoder(input_size, output_size)\n",
    "model = model.double().cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:09.499574Z",
     "end_time": "2024-03-19T15:00:09.531580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test model input output size by giving random input\n",
    "test = np.random.rand(32, 25, 36)\n",
    "print(test.shape)\n",
    "test = np.expand_dims(test, axis=1)\n",
    "print(test.shape)\n",
    "test = torch.tensor(test, dtype=torch.double).to(device)\n",
    "# print(test)\n",
    "y = model(test)\n",
    "# remove the first dimension\n",
    "print(y)\n",
    "y = y.squeeze(1)\n",
    "# print the output size\n",
    "print(y.shape)\n",
    "# print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:13.655904Z",
     "end_time": "2024-03-19T15:00:13.972795Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:16.629781Z",
     "end_time": "2024-03-19T15:00:16.645827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    for i, data in enumerate(train_loader):\n",
    "        keypoint, imu = data\n",
    "        keypoint = keypoint.double().to(device)\n",
    "        # check if keypoint has any nan values\n",
    "        # print(torch.isnan(keypoint).any())\n",
    "        imu = imu.double().to(device)\n",
    "        output = model(keypoint)\n",
    "        output = output.squeeze(1)\n",
    "        loss = criterion(output, imu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T15:00:17.708378Z",
     "end_time": "2024-03-19T15:01:27.479770Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(imu_data[(imu_data['subject'] == 7) & (imu_data['activity'] == 7)].index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T10:26:07.338582Z",
     "end_time": "2024-03-19T10:26:07.382075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T10:26:07.355581Z",
     "end_time": "2024-03-19T10:26:07.382829Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-19T10:26:07.369582Z",
     "end_time": "2024-03-19T10:26:07.404913Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
