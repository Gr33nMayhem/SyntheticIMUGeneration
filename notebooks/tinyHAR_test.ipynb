{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter, resample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy import misc\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from dataloaders.VTT_dataloader import DataSet_VTT\n",
    "from model_train.preprocess import DataPreprocess\n",
    "from models.TinyHAREncoderDecoder import TinyHAR_Encoder_Decoder_Model\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "reference_point =\n",
    "window_size =\n",
    "step_size =\n",
    "imu_position =\n",
    "learning_rate =\n",
    "batch_size =\n",
    "num_epochs =\n",
    "loss_function =\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# check if cuda is available\n",
    "print(torch.cuda.is_available())\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "data_path = '../data/VTT_ConIot_Dataset'\n",
    "IMU_path = data_path + '/IMU'\n",
    "Keypoint_path = data_path + '/Keypoint'\n",
    "activities = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "users = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "num_input_features = 36\n",
    "num_output_features = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocess = DataPreprocess(reference_point, window_size, step_size, imu_position)\n",
    "# get the processed data\n",
    "keypoint_data, imu_data, sliding_windows = preprocess.processed_data()\n",
    "\n",
    "# replace any nan value as the mean of the value before and after it\n",
    "keypoint_data = keypoint_data.fillna(keypoint_data.mean())\n",
    "imu_data = imu_data.fillna(imu_data.mean())\n",
    "\n",
    "dataset_train = DataSet_VTT(keypoint_data, imu_data, sliding_windows, 1, flag='train')\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = (window_size, num_input_features)\n",
    "output_size = (window_size, num_output_features)\n",
    "model = TinyHAR_Encoder_Decoder_Model(input_size, 5)\n",
    "model = model.double().cuda()\n",
    "if loss_function == 'cross_entropy':\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"mean\").to(device)\n",
    "else:\n",
    "    criterion = nn.MSELoss(reduction=\"mean\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# input_size = (window_size, num_input_features)\n",
    "# output_size = (window_size, num_output_features)\n",
    "# model = EncoderDecoder(input_size, output_size)\n",
    "# model = model.double().cuda()\n",
    "# if loss_function == 'cross_entropy':\n",
    "#     criterion = nn.CrossEntropyLoss(reduction=\"mean\").to(device)\n",
    "# else:\n",
    "#     criterion = nn.MSELoss(reduction=\"mean\").to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'Epoch: {epoch}')\n",
    "#     for i, data in enumerate(train_loader):\n",
    "#         keypoint, imu = data\n",
    "#         keypoint = keypoint.double().to(device)\n",
    "#         # check if keypoint has any nan values\n",
    "#         # print(torch.isnan(keypoint).any())\n",
    "#         imu = imu.double().to(device)\n",
    "#         output = model(keypoint)\n",
    "#         output = output.squeeze(1)\n",
    "#         loss = criterion(output, imu)\n",
    "#\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if i % 100 == 0:\n",
    "#             print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
